# Week 2: Computational Solutions to MDPs

## Objective
Learn how to solve Markov Decision Processes (MDPs) computationally using **Dynamic Programming**.

> "The key idea of DP, and of reinforcement learning generally, is the use of value functions to organize and structure the search for good policies." â€” Sutton & Barto

## Contents
This week covers fundamental DP algorithms:
- **Policy Evaluation**: Computing value functions for a given policy
- **Policy Iteration**: Iteratively improving policies
- **Value Iteration**: Finding optimal policies directly

## Implementation
See `week2.ipynb` for hands-on implementations of all three algorithms, including a worked example from Sutton's *Reinforcement Learning: An Introduction* (Example 4.1: Grid World).
